<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cloud | Seeking Simplicity]]></title>
  <link href="http://mattstine.com/blog/categories/cloud/atom.xml" rel="self"/>
  <link href="http://mattstine.com/"/>
  <updated>2014-07-02T15:10:40-05:00</updated>
  <id>http://mattstine.com/</id>
  <author>
    <name><![CDATA[Matt Stine]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[BOSH and Cloud API Compatibility]]></title>
    <link href="http://mattstine.com/2013/08/02/bosh-and-cloud-api-compatibility/"/>
    <updated>2013-08-02T16:10:00-05:00</updated>
    <id>http://mattstine.com/2013/08/02/bosh-and-cloud-api-compatibility</id>
    <content type="html"><![CDATA[<p>The gauntlet has again been dropped in the world of cloud interoperability. The dueling factions include those asserting that competitors to Amazon's web services (principally OpenStack) must adopt AWS's API's in order to remain viable, and those that believe such "API cloning" will do nothing more than stunt innovation. If you were to ask me, I'd say that we've seen this play out before. Remember the "Clone Wars" that began in the late 1980's and that persisted for the better part of two decades? A huge cast of competitors battled for the title of "best PC that's not manufactured by IBM." How did that play out? For a relatively short period of time, having the best PC "designed for Microsoft Windows," along with the leanest supply chain (see Dell), paved a golden path to victory. And then Steve Jobs returns to Apple, and now better than 50% of the laptops running in the Starbucks in which I'm writing this blog have a shiny white fruit on their lids. As it turns out, "going your own way" can work out awfully well.</p>

<p>But that's not the angle I want to take in this discussion. Let's dig deeper into what the two sides have to say.</p>

<p>The battle was first renewed with Cloud Scaling CTO Randy Bias' <a href="http://www.cloudscaling.com/blog/cloud-computing/openstack-aws">Open Letter to the OpenStack Community</a>. Randy adopts the position that full-compatibility with the AWS API's is necessary for OpenStack's survival. The gist of his argument is that Amazon currently dominates public cloud, supporting this via a comparison between Amazon's and Rackspace's growth rates since 2009, and that they also "control the innovation curve" as they push "new features into production at a breathtaking pace." Furthermore, he asserts that any hope for survival with respect to competing cloud platforms is limited to the hybrid cloud space, providing enterprises with the capability to seamlessly migrate workloads between the public cloud and private, on-premises clouds. Therefore, OpenStack must adopt API compatibility with AWS in order to become the enterprise choice for hybrid cloud.</p>

<p>A few days later, Rackspace's "Startup Liaison Officer" Robert Scoble responded with his own <a href="https://plus.google.com/+Scobleizer/posts/HQ7Wi4WCQse">Open Letter</a>. Scoble makes some interesting counterpoints, most notably the argument that customers don't adopt cloud platforms because of API compatibility with Amazon, but because of the promise of a "10x improvement" to their own business. In order to provide such improvements, cloud platform competitors must not shackle themselves to a "de facto standard" API, but rather must focus their limited resources on driving those 10x improvements in infrastructure capability.</p>

<p>So by now you must be wondering, whose side am I on? I'm on the side of innovation. But that doesn't necessarily put me in either camp. I think the end goals of both parties are things that we want:</p>

<ul>
<li><strong>Freedom:</strong> the ability to migrate workloads between cloud infrastructure providers without needing to significantly alter the behavior of the workload itself.</li>
<li><strong>Innovation:</strong> the ability to realize capabilities that don't exist today that will solve emerging problems (particularly those related to the explosion of generated and archived data).</li>
</ul>


<p>Spending development cycles on API compatibility will certainly slow anyone's ability to innovate. And what is API compatibility anyway? I believe that much of the concern rests on the large investment many enterprises have (or believe they will need to create) in bespoke automation written to a particular vendor's API. Having recently left a large-scale project that generated thousands of lines of such automation to drive consumption of a particular vendor's infrastucture platform, and that was in the near term planning to migrate to another platform, I can tell you that this concern is very real. But simply stating that "your existing code will work when you target our API" does not compatibility make. As Amazon continues to deploy new features at their breathtaking pace, how will OpenStack and other platforms keep up?</p>

<p>For API compatibility to be <em>real</em>, a "technology compatibility kit" (TCK) is needed. For those in the Java world, TCK's are near and dear. Java itself is not a particular implementation, but a standard API that invites competing implementations and innovation. But for any competing implementation to call itself "Java," it must pass the tests contained within the TCK. An AWS TCK is really the only true way to ensure API compatibility. But I think it's hard to argue that Amazon has any real business interest in creating and sharing one.</p>

<p>There is another way. Perhaps we should stop creating bespoke automation and rally around a common standard toolkit for managing large-scale cloud application deployments. This toolkit could provide mechanisms for configuration management, orchestration, health management, and rolling upgrades. It could further, as part of its architecture, build an adapter layer between its core components and the underlying infrastructure provider. Plugins could then be developed to provide the toolkit with the ability to manage all of the common infrastructure providers.</p>

<p>Enter BOSH and it's Cloud Provider Interface (CPI) layer. BOSH was initially developed as the means of deploying and managing the Cloud Foundry PaaS platform, but it's much more generally applicable. BOSH can today deploy any distributed system, <em>unchanged</em>, to any of several popular IaaS providers: VMware vSphere, VMware vCloud Director, Amazon Web Services, and OpenStack. Heresy you say! Not so. Just ask Colin Humphreys of CloudCredo, who recently <a href="http://blog.cloudfoundry.com/2013/04/30/uk-charity-raises-record-donations-powered-by-cloud-foundry">described their wildly successful deployment</a> of Cloud Foundry to a hybrid composition of vSphere and AWS-based clouds. He recently presented a technical deep dive in Pivotal's offices in which he made the statement (paraphrasing) "I took the same Cloud Foundry bits that were running on AWS and deployed them unchanged to vSphere using BOSH." As anyone can tell, this isn't just theory, it's production.</p>

<p>So how then does BOSH make this happen? A trip <a href="https://github.com/cloudfoundry/bosh/blob/master/bosh_cpi/lib/cloud.rb">into the code</a> for the BOSH CPI "interface" will show a list of core infrastructure capabilities that BOSH requires:</p>

<ul>
<li><code>current_vm_id</code></li>
<li><code>create_stemcell</code></li>
<li><code>delete_stemcell</code></li>
<li><code>create_vm</code></li>
<li><code>delete_vm</code></li>
<li><code>has_vm?</code></li>
<li><code>reboot_vm</code></li>
<li><code>set_vm_metadata</code></li>
<li><code>configure_networks</code></li>
<li><code>create_disk</code></li>
<li><code>delete_disk</code></li>
<li><code>attach_disk</code></li>
<li><code>snapshot_disk</code></li>
<li><code>delete_snapshot</code></li>
<li><code>detach_disk</code></li>
<li><code>get_disks</code></li>
</ul>


<p>All interactions between BOSH and the underlying infrastructure provider pass through these core methods. As long as a CPI exists that exposes these capabilities to BOSH, BOSH can deploy and manage the lifecycle of Cloud Foundry (or any other distributed system described by a BOSH release) on an infrastructure provider.</p>

<p>So how hard is it to provide the CPI's for both AWS and OpenStack? If you choose simple metrics like number of classes (NOC) and lines of code (LOC), not that hard.</p>

<p>You can find the CPI implementations at these links:</p>

<ul>
<li><a href="https://github.com/cloudfoundry/bosh/tree/master/bosh_aws_cpi">https://github.com/cloudfoundry/bosh/tree/master/bosh_aws_cpi</a></li>
<li><a href="https://github.com/cloudfoundry/bosh/tree/master/bosh_openstack_cpi">https://github.com/cloudfoundry/bosh/tree/master/bosh_openstack_cpi</a></li>
</ul>


<p>First we'll generate the metrics for AWS:</p>

<p>``` bash
$ find ./bosh_aws_cpi/lib -name "*.rb" -exec wc -l {} \;</p>

<pre><code>   2 ./bosh_aws_cpi/lib/bosh_aws_cpi.rb
  68 ./bosh_aws_cpi/lib/cloud/aws/aki_picker.rb
  39 ./bosh_aws_cpi/lib/cloud/aws/availability_zone_selector.rb
 651 ./bosh_aws_cpi/lib/cloud/aws/cloud.rb
  22 ./bosh_aws_cpi/lib/cloud/aws/dynamic_network.rb
  30 ./bosh_aws_cpi/lib/cloud/aws/helpers.rb
 171 ./bosh_aws_cpi/lib/cloud/aws/instance_manager.rb
  25 ./bosh_aws_cpi/lib/cloud/aws/manual_network.rb
  37 ./bosh_aws_cpi/lib/cloud/aws/network.rb
  89 ./bosh_aws_cpi/lib/cloud/aws/network_configurator.rb
 189 ./bosh_aws_cpi/lib/cloud/aws/resource_wait.rb
  68 ./bosh_aws_cpi/lib/cloud/aws/stemcell.rb
 114 ./bosh_aws_cpi/lib/cloud/aws/stemcell_creator.rb
  30 ./bosh_aws_cpi/lib/cloud/aws/tag_manager.rb
   7 ./bosh_aws_cpi/lib/cloud/aws/version.rb
  44 ./bosh_aws_cpi/lib/cloud/aws/vip_network.rb
  43 ./bosh_aws_cpi/lib/cloud/aws.rb
</code></pre>

<p>```
We'll also want the total LOC:</p>

<p><code>bash
$ find ./bosh_aws_cpi/lib -name "*.rb" -exec wc -l {} \; | awk '{ sum += $1 } END { print sum }'
1629
</code></p>

<p>And now let's do the same for OpenStack:</p>

<p>``` bash
$ find ./bosh_openstack_cpi/lib -name "*.rb" -exec wc -l {} \;</p>

<pre><code>   4 ./bosh_openstack_cpi/lib/bosh_openstack_cpi.rb
 867 ./bosh_openstack_cpi/lib/cloud/openstack/cloud.rb
  28 ./bosh_openstack_cpi/lib/cloud/openstack/dynamic_network.rb
 131 ./bosh_openstack_cpi/lib/cloud/openstack/helpers.rb
  34 ./bosh_openstack_cpi/lib/cloud/openstack/manual_network.rb
  37 ./bosh_openstack_cpi/lib/cloud/openstack/network.rb
 159 ./bosh_openstack_cpi/lib/cloud/openstack/network_configurator.rb
  16 ./bosh_openstack_cpi/lib/cloud/openstack/tag_manager.rb
   8 ./bosh_openstack_cpi/lib/cloud/openstack/version.rb
  50 ./bosh_openstack_cpi/lib/cloud/openstack/vip_network.rb
  39 ./bosh_openstack_cpi/lib/cloud/openstack.rb
</code></pre>

<p>$ find ./bosh_openstack_cpi/lib -name "*.rb" -exec wc -l {} \; | awk '{ sum += $1 } END { print sum }'
1373
```</p>

<p>So, summarizing:</p>

<table>
<thead>
<tr>
<th>CPI        </th>
<th align="right"> Number of Classes (NOC) </th>
<th align="right"> Lines of Code (LOC)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Amazon AWS </td>
<td align="right"> 17                      </td>
<td align="right"> 1629</td>
</tr>
<tr>
<td>OpenStack  </td>
<td align="right"> 11                      </td>
<td align="right"> 1373</td>
</tr>
</tbody>
</table>


<br/>


<p>Let's make a couple of points about these metrics. First of all, the two CPI's do not use a common foundation. The AWS CPI uses the <a href="http://aws.amazon.com/sdkforruby">AWS SDK for Ruby</a> while the OpenStack CPI uses <a href="http://fog.io">Fog</a>. Fog could also have been used as the foundation for the AWS CPI, but the CPI authors presumably thought it better to stick with the toolkit provided by Amazon. This is a minor point, however, as both of these toolkits essentially provide simple wrappers around the infrastructure providers' REST API's. It's doubtful that using a common API wrapper for both CPI's would have substantially changed the metrics presented here.</p>

<p>Second, obviously NOC and LOC are rather naive metrics. It's incredibly possible to write terse code that is opaque, buggy, and hard to maintain or enhance. In fact, according to Code Climate, both of the top-level implementation classes for these CPI's have quite a lot of room for improvement:</p>

<ul>
<li><a href="https://codeclimate.com/github/cloudfoundry/bosh/Bosh::AwsCloud::Cloud">https://codeclimate.com/github/cloudfoundry/bosh/Bosh::AwsCloud::Cloud</a></li>
<li><a href="https://codeclimate.com/github/cloudfoundry/bosh/Bosh::OpenStackCloud::Cloud">https://codeclimate.com/github/cloudfoundry/bosh/Bosh::OpenStackCloud::Cloud</a></li>
</ul>


<p>With that said, it is rather amazing that one could encapuslate all of the infrastructure-specific implementation necessary to deploy and manage a distributed system as powerful as Cloud Foundry in <em>less than twenty classes and 1700 lines of code</em>.</p>

<p>So, to summarize where we've been, while there's an impressive war of words out there regarding API compatibility with Amazon AWS, Cloud Foundry and BOSH don't necessarily need to take sides. If OpenStack chooses to embrace the AWS API's, the BOSH AWS CPI will be there waiting. However, if OpenStack chooses to follow in the footsteps of Apple and take the road less traveled, the OpenStack CPI is ready and waiting to evolve with it. Should Google Compute Engine or Microsoft's Azure gain a foodhold on the innovation curve, they are presumably a relatively simple CPI away from joining the BOSH ecosystem. So if you really want "cloud freedom," BOSH is leading the charge.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Blue-Green Deployments on Cloud Foundry]]></title>
    <link href="http://mattstine.com/2013/07/10/blue-green-deployments-on-cloudfoundry/"/>
    <updated>2013-07-10T20:10:00-05:00</updated>
    <id>http://mattstine.com/2013/07/10/blue-green-deployments-on-cloudfoundry</id>
    <content type="html"><![CDATA[<p>One of the great things about Cloud Foundry is that it is a great enabler. Tall words. But what do they mean? Essentially, Cloud Foundry (and any other well-designed PaaS) enables us to do things as developers and operators that would be extremely difficult in a traditional deployment environments. One particularly valuable area of enablement is our new found ability to practice <a href="http://continuousdelivery.com/">Continous Delivery</a>, meaning that we continuously prove our ability to deliver working software by continuously treating each code commit to a system as if it could be deployed to a production environment. We do this by shipping these commits through what's called a "deployment pipeline," which consists of a series of build-test-deploy cycles that prove out a commit's suitability for production deployment. At the end of the pipeline we can either deploy automatically to our production environment (i.e. continuous deployment), or we can have a business decision to deploy that "deployable artifact" or not.</p>

<p>One particular practice associated with Continuous Delivery is <a href="http://martinfowler.com/bliki/BlueGreenDeployment.html">Blue-Green Deployments</a>. Martin Fowler describes these very well at the link provided, but I'll summarize briefly here:</p>

<ul>
<li>Cut-over to a new software version is tricky, and must be quick in order to minimize downtime events.</li>
<li>Blue-green deployments ensure the parallel existence of two, identical (as possible) production environments.</li>
<li>At any given point, only one (e.g. blue) services production traffic.</li>
<li>New deploys are made to the other (e.g. green) environment. Final smoke testing is performed here.</li>
<li>When green is determined ready, we begin routing traffic to it.</li>
<li>We then stop routing traffic to blue.</li>
</ul>


<p>Of course, there are several concerns that must be dealt with at the application level in order for this to work (datastores should support concurrent usage by two app versions, long running requests may be killed, etc.). What we'll focus on in this post is how Cloud Foundry supports the mechanics summarized above.</p>

<p>We'll begin with a basic Spring application named <code>ms-spr-demo</code>. This app takes users to a simple web page announcing the ubiquitous "Hello World!" message. We'll utilize the <code>cf</code> command-line interface to push the application:</p>

<p>``` bash
$ cf push --path build/libs/cf-demo.war
Name> ms-spr-demo</p>

<p>Instances> 1</p>

<p>Memory Limit> 512M</p>

<p>Creating ms-spr-demo... OK</p>

<p>1: ms-spr-demo
2: none
Subdomain> ms-spr-demo</p>

<p>1: cfapps.io
2: mattstine.com
3: none
Domain> 1</p>

<p>Creating route ms-spr-demo.cfapps.io... OK
Binding ms-spr-demo.cfapps.io to ms-spr-demo... OK</p>

<p>Create services for application?> n</p>

<p>Save configuration?> y</p>

<p>Saving to manifest.yml... OK
Uploading ms-spr-demo... OK
Starting ms-spr-demo... OK
-----> Downloaded app package (9.5M)
Installing java.
Downloading JDK...
Copying openjdk-1.7.0_25.tar.gz from the buildpack cache ...
Unpacking JDK to .jdk
Downloading Tomcat: apache-tomcat-7.0.41.tar.gz
Copying apache-tomcat-7.0.41.tar.gz from the buildpack cache ...
Unpacking Tomcat to .tomcat
Copying mysql-connector-java-5.1.12.jar from the buildpack cache ...
Copying postgresql-9.0-801.jdbc4.jar from the buildpack cache ...
Copying auto-reconfiguration-0.6.8.jar from the buildpack cache ...
-----> Uploading droplet (48M)
-----> Uploaded droplet
Checking ms-spr-demo...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  1/1 instances: 1 running
OK
```</p>

<p>The end result of this <code>cf push</code> event is that an application is now serving requests at <code>http://ms-spr-demo.cfapps.io</code>. The following graphic shows the state of our system, with the CF Router sending traffic to our application:</p>

<p><img class="center" src="/images/blue-green/BlueGreen1.png"></p>

<p>Next, we make a slight change to our application. Rather that saying "Hello World!" we decide to make it say "Goodbye World!" We build a new war file for the application. Rather than letting <code>cf</code> prompt us this time, we'll make use of the <code>manifest.yml</code> file that we saved from our previous push. However, we'll rename the application and provide a new route. Take a look:</p>

<h2>``` </h2>

<p>applications:
- name: ms-spr-demo-green
  memory: 512M
  instances: 1
  url: ms-spr-demo-green.cfapps.io
  path: build/libs/cf-demo.war
```</p>

<p>As you can see, we're calling our new application version <code>ms-spr-demo-green</code> and we're mapping it to the URL <code>ms-spr-demo-green.cfapps.io</code>. Let's push the application:</p>

<p>``` bash
Using manifest file manifest.yml</p>

<p>Creating ms-spr-demo-green... OK</p>

<p>1: ms-spr-demo-green
2: none
Subdomain> ms-spr-demo-green</p>

<p>1: cfapps.io
2: mattstine.com
3: none
Domain> 1</p>

<p>Creating route ms-spr-demo-green.cfapps.io... OK
Binding ms-spr-demo-green.cfapps.io to ms-spr-demo-green... OK
Uploading ms-spr-demo-green... OK
Starting ms-spr-demo-green... OK
-----> Downloaded app package (9.5M)
Installing java.
Downloading JDK...
Copying openjdk-1.7.0_25.tar.gz from the buildpack cache ...
Unpacking JDK to .jdk
Downloading Tomcat: apache-tomcat-7.0.41.tar.gz
Copying apache-tomcat-7.0.41.tar.gz from the buildpack cache ...
Unpacking Tomcat to .tomcat
Copying mysql-connector-java-5.1.12.jar from the buildpack cache ...
Copying postgresql-9.0-801.jdbc4.jar from the buildpack cache ...
Copying auto-reconfiguration-0.6.8.jar from the buildpack cache ...
-----> Uploading droplet (48M)
-----> Uploaded droplet
Checking ms-spr-demo-green...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
Staging in progress...
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  0/1 instances: 1 starting
  1/1 instances: 1 running
OK
```</p>

<p>We now have two instances of the application running, each of them using distinct routes:</p>

<p><img class="center" src="/images/blue-green/BlueGreen2.png"></p>

<p>Now it's time for the magic to happen. We'll map our original URL route (<code>ms-spr-demo.cfapps.io</code>) to our "green" instance. This is accomplished very simply by using <code>cf</code>:</p>

<p><code>bash
cf map --app ms-spr-demo-green --host ms-spr-demo --domain cfapps.io
Binding ms-spr-demo.cfapps.io to ms-spr-demo-green... OK
</code></p>

<p>The CF router immediately begins to load balance requests between each instance of the application, as shown here:</p>

<p><img class="center" src="/images/blue-green/BlueGreen3.png"></p>

<p>Now our router will send requests to <code>ms-spr-demo.cfapps.io</code> to both instances of the application, while <code>ms-spr-demo-green.cfapps.io</code> only services the "green" instance. Once we determine that all is well, it's time to stop routing requests to the "blue" instance. This is just as simple using <code>cf</code>:</p>

<p><code>bash
cf unmap --url ms-spr-demo.cfapps.io --app ms-spr-demo
Unbinding ms-spr-demo.cfapps.io from ms-spr-demo... OK
</code></p>

<p>Our "blue" instance is now no longer receiving any web traffic:</p>

<p><img class="center" src="/images/blue-green/BlueGreen4.png"></p>

<p>We can now decomission our "blue" instance, or we can leave it around for a period of time in case we decide we need to roll back our changes. The important thing is that our customers suffered absolutely no downtime!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Into the Crucible]]></title>
    <link href="http://mattstine.com/2013/05/29/into-the-crucible/"/>
    <updated>2013-05-29T09:00:00-05:00</updated>
    <id>http://mattstine.com/2013/05/29/into-the-crucible</id>
    <content type="html"><![CDATA[<p>Wow...it seems I only post to this blog toward the end of May. Well, that all changes now. You see, as of June 3, 2013, this blog is going to become one of many aspects of my new "day job." On Monday, I start my life as a Community Engineer with <a href="http://cloudfoundry.com">Cloud Foundry</a> by <a href="http://goPivotal.com">Pivotal</a>. What's a Community Engineer? Quite honestly, I'm not completely sure of the answer to that question yet. But given the many conversations I've had over the past few weeks, it seemingly fits right in with the bridge-building roles I've played many times over the course of my career. In this case, I have one foot squarely planted in the world of Cloud Foundry engineering, and one foot squarely planted out in the world with you guys and gals - the community. My job is to help you understand how we are quite literally seeking to "build a new platform for a new era."</p>

<p>Of course, this is a journey that for me started a few years ago. In my previous life as a front-line development manager, I helped lead an agile transformation within my team with "ruthless automation" playing a central role in everything that our team did. However, it seemed that the better we "did agile," the more pain we felt when dealing with those outside of our circle of control. It was only years later, after reading Eliyahu Goldratt's <a href="http://en.wikipedia.org/wiki/The_Goal_(novel)">The Goal</a> and coming to an understanding of his <a href="http://en.wikipedia.org/wiki/Theory_of_Constraints">Theory of Constraints</a>, that I realized what was happening. Our constraints had moved "out of the plant," if you will, and landed in the world of operations. Even without this understanding, I developed a keen interest in this newly emerging topic called "DevOps" and began to explore the ideas emerging around agile operations and infrastructure as code. I started playing with tools like Puppet, Chef, and Vagrant, and taught sessions on all three of them at the Project Automation Experience in 2011.</p>

<p>You can read my <a href="http://www.mattstine.com/2012/05/24/the-relaunch/">last entry</a> and find out that not much later I joined VMware as a Senior Consultant for its Cloud Application Platform. I was hired into that role based on my extensive background in enterprise Java and the Spring ecosystem, but it was nothing short of a staffing accident that I found myself thrust into a role on a virtualization platform provisioning team helping to build out a private self-service cloud! I was steadily getting carried further away from my role as an application architect, steadily becoming assimilated into that mysterious world of web operations that I knew so little about. These experiences, along with my continued reading and thinking about the worlds of DevOps, Lean, and Kanban, have quite literally changed the way I look at the world of software engineering (or as I prefer to think of it now, value delivery through product engineering that just so happens to involve software!). These experiences have formed around me a <a href="http://en.wikipedia.org/wiki/Crucible">crucible</a>, melting me that I might be poured into a new professional mold.</p>

<p>So now it's time to plunge into the world of building the leading <a href="http://wattersjames.com/2013/03/04/my-fork-you-shirt/">open</a> platform as a service, and to help YOU experience the <a href="https://twitter.com/mstine/status/339570787914760195">HUGE can of @cloudfoundry awesome</a> that we at Pivotal are about to unleash on the world. Sound good to you? <a href="http://blog.cloudfoundry.com/2013/05/16/want-to-contribute-to-cloud-foundry-come-on-in/">Join us!</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Announcing NOSQL Summer Memphis]]></title>
    <link href="http://mattstine.com/2010/05/28/announcing-nosql-summer-memphis/"/>
    <updated>2010-05-28T09:21:43-05:00</updated>
    <id>http://mattstine.com/2010/05/28/announcing-nosql-summer-memphis</id>
    <content type="html"><![CDATA[<p>I recently stumbled across the <a href="http://nosqlsummer.org/">NOSQL Summer</a> website via my friend Alex Miller's <a href="http://tech.puredanger.com/2010/05/25/nosql-summer-st-louis/">blog</a>. The idea is to setup a summer reading club focused around databases and distributed systems. Groups will gather "worldwide" to discuss various papers and the hopefully submit the substance of their discussions back to the NOSQL Summer website in the form of annotated papers.</p>

<p>This sounded like a great idea to me, so I decided that we'd co-locate a NOSQL Summer discussion with our monthly Memphis JUG meetings. You can find the details of our NOSQL meetings at <a href="http://nosqlsummer.org/city/memphis">http://nosqlsummer.org/city/memphis</a>. We'll start at 5:30 and run until 6:15-6:30. If you're interested in these discussions, come on out to Southwest TN Community College on June 24th (even if you're not a Java type!).</p>

<p>Our first paper will be <a href="http://nosqlsummer.org/paper/end-of-architectural-era">The End of an Architectural Era (It's Time for a Complete Rewrite)</a>. Please read it before the meeting and come prepared to mindshare.</p>

<p>If there's enough interest in these discussions, we could start having a lunch time discussion at a centrally located restaurant halfway between each JUG meeting. We can discuss this at our first meeting in June. I hope to see you there!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying Grails to Morph AppSpace: #CommunityOne 2009 Lightning Talk]]></title>
    <link href="http://mattstine.com/2009/06/01/deploying-grails-to-morph-appspace-communityone-2009-lightning-talk/"/>
    <updated>2009-06-01T23:56:06-05:00</updated>
    <id>http://mattstine.com/2009/06/01/deploying-grails-to-morph-appspace-communityone-2009-lightning-talk</id>
    <content type="html"><![CDATA[<p>I gave two lightning talks at <a href="http://developers.sun.com/events/communityone/2009/west/index.jsp">CommunityOne</a> today, the first of which described deploying <a href="http://grails.org">Grails</a> applications to <a href="http://mor.ph/products_appspace">Morph AppSpace</a>.</p>

<p>For the uninitiated, Grails is a Ruby on Rails inspired full stack web development framework which brings "convention over configuration" and "DRY" into the Java web development arena. Unlike Rails, it is not an effort from scratch, but rather stands on the shoulders of proven giants in the Java world like the Spring framework and Hibernate. It does this using Groovy, the popular dynamic scripting language for the JVM, as a sort of "DSL for web development." Find it at <a href="http://grails.org">http://grails.org</a>.</p>

<p>Morph AppSpace on the other hand is a fully-configured and managed environment for hosting web applications, and currently supports Java, Grails, Rails, and PHP applications. It is a "platform as a service" (PaaS) provider that abstracts away the details of Amazon EC2 and S3 technologies. Systems architecture, backups, monitoring, failover, scalability - all of this is handled by Morph. You simply develop and deploy your application - Morph does the rest. Find it at <a href="http://mor.ph/products_appspace">http://mor.ph/products_appspace</a>.</p>

<p>So to get going, visit <a href="http://mor.ph">http://mor.ph</a> and sign up for a free developer account. Create yourself a Java application subscription, and pick your choice of database (MySQL or PostgreSQL). Create the database, and then download two very important files into the root directory of your Grails project: deployment.properties, which contains the metadata describing your application to the Morph AppSpace platform, and morph_deployer.jar, which contains the client API to the platform.</p>

<p>Next you'll need to install the <a href="http://grails.org/plugin/morph-deploy">Grails morph-deploy plugin</a>. If you're using Grails 1.1, you'll need to checkout <a href="https://svn.codehaus.org/grails-plugins/grails-morph-deploy/trunk/">the trunk version from SVN</a>, as the version in the plugin repository is not 1.1 ready. Install this plugin locally by running "grails install-plugin $PATH_TO_PLUGIN." Next, you'll need to edit DataSource.groovy to contain the following:</p>

<pre><code>production {
        dataSource {
            driverClassName = 'com.mysql.jdbc.Driver'
            dbCreate = "update"
            jndiName = "java:comp/env/jdbc/morph-ds"
            dialect = 'org.hibernate.dialect.MySQLDialect'
        }
}
</code></pre>

<p>Finally, run "grails war" to build the war file, and "grails deploy" to upload your application to the platform. Once the upload is complete, visit the management interface and check the logs to see that you've successfully deployed. Once it's finished, click on the link to your application. Happy Grails on the cloud!</p>

<p>Here's the screencast from my talk. Enjoy!</p>

<p>[youtube=http://www.youtube.com/watch?v=JYPJ26-1YTM&hl;=en&fs;=1&border;=1]</p>
]]></content>
  </entry>
  
</feed>
